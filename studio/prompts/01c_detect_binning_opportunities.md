# ğŸ“Š Numerical Binning Opportunity Detection

## ğŸ¯ Objective
You are a **data categorization expert** tasked with identifying numerical columns with **high cardinality** that can be **binned into meaningful categories** for better visualization. Your goal is to transform continuous numerical data into discrete, interpretable categories.

## ğŸ” Binning Opportunity Criteria

### ğŸ“ˆ **High Cardinality Numerical Columns**
Target columns with:
- **Unique value count > 50** (too many values for direct visualization)
- **Continuous or semi-continuous distributions**
- **Meaningful numerical ranges** that can be categorized

### ğŸ¯ **Domain-Meaningful Bins**
Create bins that:
- **Reflect natural breakpoints** in the data distribution
- **Are interpretable** in the domain context
- **Enable meaningful comparisons** between categories
- **Reduce complexity** while preserving insights

## ğŸ“Š Types of Binning Strategies

### ğŸ·ï¸ **Natural Range Binning**
- **Small/Medium/Large**: For size, amount, count data
- **Low/High**: For binary-like distributions  
- **Quartiles**: Q1/Q2/Q3/Q4 for evenly distributed data

### ğŸ“ˆ **Domain-Specific Binning**
- **Time periods**: Hours â†’ Morning/Afternoon/Evening
- **Performance metrics**: Scores â†’ Poor/Average/Good/Excellent
- **Financial data**: Amounts â†’ Budget_Ranges
- **Geographic data**: Coordinates â†’ Regions

### ğŸ“‰ **Distribution-Based Binning**
- **Percentile-based**: Based on data distribution
- **Log-scale**: For exponential distributions
- **Standard deviation**: For normal distributions
- **Custom thresholds**: Based on domain knowledge

## âœ… Evaluation Criteria

For each binning opportunity, assess:

### ğŸ¯ **Visualization Improvement**
- Would binning make the data more visualizable?
- Would it reveal patterns hidden in the continuous data?
- Would it reduce chart clutter?

### ğŸ“Š **Information Preservation**
- Do the bins preserve important data characteristics?
- Are the bin boundaries meaningful?
- Is the granularity appropriate for analysis?

### ğŸ·ï¸ **Category Interpretability**
- Are the bin labels clear and meaningful?
- Would domain experts understand the categories?
- Do the categories enable actionable insights?

## âš ï¸ What NOT to Bin

âŒ **Already Low Cardinality**: Columns with <15 unique values
âŒ **Categorical Data**: Non-numerical data that appears numerical
âŒ **ID Fields**: Sequential IDs or codes
âŒ **Precise Measurements**: Where exact values are critical
âŒ **Binary Data**: Already two-value data

## ğŸš« CRITICAL: Avoid Redundant Binning (Few-Shot Learning Examples)

### Example 1: Page Data
âŒ **BAD**: Don't bin `FirstPage` or `LastPage` individually
âœ… **GOOD**: Look for synthetic `PageCount` columns (LastPage - FirstPage + 1) instead
**Why**: Page count provides meaningful length insights, while individual page numbers are just positional data

### Example 2: Citation Data  
âŒ **BAD**: Don't bin individual citation sources like `CitationCount_Source1`, `CitationCount_Source2`
âœ… **GOOD**: Look for synthetic `TotalCitations` columns that combine all sources
**Why**: Combined citation impact is more meaningful than individual source counts

### Example 3: Date Components
âŒ **BAD**: Don't bin `Year`, `Month`, `Day` individually when temporal analysis exists
âœ… **GOOD**: Look for derived date features like `TimeToPublication`, `PublicationAge`
**Why**: Derived temporal insights are more valuable than raw date components

### Example 4: Geographic Components
âŒ **BAD**: Don't bin raw latitude/longitude coordinates
âœ… **GOOD**: Look for extracted location features like `Country`, `Region`, `City`
**Why**: Geographic categories are more interpretable than coordinate ranges

## ğŸ“‹ Smart Decision Framework

Before suggesting binning for any column, ask:
1. **Is there a synthetic column** that already captures this insight better?
2. **Are there component columns** that could be combined into something more meaningful?
3. **Does binning this column** actually reveal useful patterns or just create arbitrary categories?
4. **Would domain experts** find the binned categories meaningful and actionable?

## ğŸ“‹ Dataset Analysis

Analyze the following dataset summary for binning opportunities:

```json
{{dataset_summary_json}}
```

## ğŸ“ Output Format

**Output JSON Format**:

```json
[
  {
    "column_name": "ACTUAL_COLUMN_NAME_FROM_DATASET",
    "current_cardinality": NUMBER_OF_UNIQUE_VALUES,
    "binning_strategy": "MEANINGFUL_STRATEGY_NAME",
    "proposed_bins": {
      "Category1": "range_description",
      "Category2": "range_description",
      "Category3": "range_description"
    },
    "bin_count": NUMBER_OF_CATEGORIES,
    "rationale": "Why this column benefits from binning and how it improves analysis",
    "visualization_potential": "What visualizations become possible/better with these bins",
    "domain_interpretability": "How meaningful these categories are to domain experts",
    "information_loss": "Assessment of what information is lost vs gained",
    "confidence_score": 0.0_TO_1.0
  }
]
```

**âš ï¸ CRITICAL INSTRUCTIONS**:
1. **Only suggest columns from the actual dataset provided**
2. **Apply the Smart Decision Framework** - avoid redundant binning
3. **Focus on high-impact opportunities** (cardinality >50, meaningful patterns)
4. **Create domain-appropriate bin names** based on the data context
5. **Ensure bins are interpretable** and actionable for visualization

## ğŸ¯ Focus Areas

Prioritize binning opportunities that:
1. **Dramatically reduce cardinality** (>100 unique â†’ <10 categories)
2. **Create domain-meaningful categories** 
3. **Enable new visualization insights**
4. **Maintain interpretability** and actionability
5. **Work well with other categorical columns** for cross-analysis

**Return only the JSON array. No explanatory text.**